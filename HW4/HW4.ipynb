{
  "metadata": {
    "name": "HW6",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.storage.StorageLevel"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## SparkSession\nКонфигурация spark https://spark.apache.org/docs/latest/configuration.html"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val spark \u003d SparkSession.builder()\n    // адрес мастера\n    .master(\"local[*]\")\n    // имя приложения в интерфейсе спарка\n    .appName(\"made-demo\")\n//     .config(\"spark.executor.memory\",  \"2g\")\n//     .config(\"spark.executor.cores\", \"2\")\n//     .config(\"spark.driver.memory\", \"2g\")\n    .getOrCreate()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Импортируем синтаксический сахар."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import spark.implicits._"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Загрузим данные https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df \u003d spark.read\n            .option(\"header\", \"true\")\n            .option(\"inferSchema\", \"true\")\n            .csv(\"data/tripadvisor_hotel_reviews.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "df.show(20, 75)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "1. Привести все к одному регистру\n2. Удалить все спецсимволы"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df_stage_2 \u003d df.select(col(\"Rating\"), (lower(regexp_replace(col(\"Review\"), \"[^a-zA-Z\\\\s]\", \"\")).alias(\"text\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "df_stage_2.show(20, 75)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "3. Посчитать частоту слова в предложении"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n// val df_stage_2_ \u003d df_stage_2.select(split(col(\"text\"), \" \"))\n//     .as[Array[String]]\nval df_stage_2_ \u003d df_stage_2\n    .withColumn(\"doc_id\", monotonically_increasing_id())\n    .withColumn(\"token\", explode(split(col(\"text\"), \" \")))\n    .select(\"doc_id\", \"token\", \"text\")\n    .filter(\"token !\u003d \u0027\u0027\")"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "df_stage_2_.show(20, 75)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tf \u003d df_stage_2_.groupBy(\"doc_id\", \"token\").agg(count(\"text\") as \"tf\")"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tf.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "4. Посчитать количество документов со словом"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df \u003d df_stage_2_.groupBy(\"token\").agg(countDistinct(\"doc_id\") as \"df\")"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "df.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "5. Взять только 100 самых встречаемых"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val top_tf \u003d tf.select(\"doc_id\", \"token\", \"tf\").orderBy(col(\"tf\").desc).limit(100)\ntop_tf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val top_df \u003d df.select(\"token\", \"df\").orderBy(col(\"df\").desc).limit(100)\ntop_df.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "6. Сджойнить две полученные таблички и посчитать Tf-Idf (только для слов из предыдущего пункта)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val D \u003d tf.groupBy().agg(countDistinct(\"doc_id\") as \"val\").select(\"val\").as[String].collect()(0).toInt;\nval tf_idf \u003d top_tf\n    .join(top_df, \"token\")\n    .withColumn(\"idf\", log((col(\"df\") + 1) / (D + 1)) * (-1))\n    .withColumn(\"tf_idf\", col(\"tf\") * col(\"idf\"));\ntf_idf.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "7. Запайвотить табличку"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tf_idf.groupBy().agg(countDistinct(\"doc_id\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tf_idf.groupBy().agg(countDistinct(\"token\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val result \u003d tf_idf\n    .groupBy(\"doc_id\")\n    .pivot(col(\"token\"))\n    .agg(avg(\"tf_idf\"))\n\nresult.show"
    }
  ]
}